{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "play_seq.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM//tIOHmjnCJTrBC5Nj8m+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/myazdani/hacking-minGPT/blob/main/play_seq.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfAysbgbIF1B",
        "outputId": "ac96da98-4f97-4ad3-8652-c4f84cb4e741"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'hacking-minGPT'...\n",
            "remote: Enumerating objects: 98, done.\u001b[K\n",
            "remote: Counting objects: 100% (98/98), done.\u001b[K\n",
            "remote: Compressing objects: 100% (67/67), done.\u001b[K\n",
            "remote: Total 98 (delta 61), reused 62 (delta 29), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (98/98), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/myazdani/hacking-minGPT.git\n",
        "\n",
        "import sys\n",
        "  \n",
        "# adding Folder_2 to the system path\n",
        "sys.path.insert(0, './hacking-minGPT/')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## only needed if running on google colab\n",
        "!wget https://raw.githubusercontent.com/myazdani/attention-layer-demo/master/utils.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yNpL6Py9IG-C",
        "outputId": "bb8876a6-44bc-4b62-dbe5-ead2914c8712"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-07-10 06:29:58--  https://raw.githubusercontent.com/myazdani/attention-layer-demo/master/utils.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3583 (3.5K) [text/plain]\n",
            "Saving to: ‘utils.py’\n",
            "\n",
            "utils.py            100%[===================>]   3.50K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-07-10 06:29:59 (40.4 MB/s) - ‘utils.py’ saved [3583/3583]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import utils\n",
        "\n",
        "data_gen = utils.DataUtil(seq_height_min = 1.0, \n",
        "                          seq_height_max = 25.0,\n",
        "                          seq_width_min = 5.0, \n",
        "                          seq_width_max = 11.0,\n",
        "                          seq_length = 100,\n",
        "                          group_by_locations = False\n",
        "                         )"
      ],
      "metadata": {
        "id": "R3Gkb51pILS4"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set up logging\n",
        "import logging\n",
        "logging.basicConfig(\n",
        "        format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
        "        datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
        "        level=logging.INFO,\n",
        ")"
      ],
      "metadata": {
        "id": "9EjyTNQMIOYX"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make deterministic\n",
        "from mingpt.utils import set_seed\n",
        "set_seed(42)"
      ],
      "metadata": {
        "id": "YRtkrvF4IT3E"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F"
      ],
      "metadata": {
        "id": "BeJuUOCWIW-Z"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_input, train_targets, train_tr, train_bx = data_gen.generate_sequences(25000)\n",
        "test_input, test_targets, test_tr, test_bx = data_gen.generate_sequences(1000)"
      ],
      "metadata": {
        "id": "sB0nzbcfIabR"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_input[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvx6legcIiNg",
        "outputId": "9de5bb4f-63b3-49db-bca5-23aff2da78ac"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.3881e-01,  6.3907e-04,  3.5653e-02, -1.0254e-01, -1.4928e-02,\n",
              "         -9.7536e-02, -8.0082e-02,  1.4810e-01, -4.3043e-02, -1.1965e-01,\n",
              "         -6.2651e-03,  8.9815e-02, -6.1008e-03, -1.2954e-01, -1.2650e-01,\n",
              "          5.6362e-02,  1.8373e+01,  1.8453e+01,  1.8570e+01,  1.8533e+01,\n",
              "          1.8387e+01,  1.8613e+01,  6.8205e-02, -1.0463e-01,  2.1756e-01,\n",
              "          3.4020e+00,  6.7923e+00,  9.9844e+00,  1.3520e+01,  1.6784e+01,\n",
              "          1.6550e+01,  1.3446e+01,  1.0037e+01,  6.8722e+00,  3.4742e+00,\n",
              "          1.3080e-01,  7.2165e-02, -3.5473e-02,  9.8057e-02,  1.3551e-01,\n",
              "          1.4653e-01,  1.1693e+00,  2.7657e+00,  4.2827e+00,  5.9463e+00,\n",
              "          6.4351e+00,  5.1312e+00,  3.8046e+00,  2.0117e+00,  5.1997e-01,\n",
              "         -8.3284e-02, -2.7345e-02,  1.3278e-01, -3.3797e-02,  5.6181e-03,\n",
              "          8.7424e-03, -2.9240e-02,  8.0360e-02, -6.2150e-02,  3.8748e-02,\n",
              "          1.1138e-01,  1.4885e-01, -8.2257e-02, -5.1634e-02, -1.2590e-01,\n",
              "          1.4295e-01, -7.3140e-02, -3.6933e-02,  1.7170e+01,  1.7046e+01,\n",
              "          1.7106e+01,  1.7189e+01,  1.7049e+01,  1.7287e+01,  1.7299e+01,\n",
              "         -8.9969e-02,  8.7771e-02, -1.1579e-01,  5.5644e-02, -1.4742e-01,\n",
              "         -4.2365e-02,  1.2633e-01,  1.0880e-01,  9.6695e-02,  7.4288e-03,\n",
              "          2.6443e-02, -6.7618e-02, -3.6278e-02, -6.0759e-02,  4.3486e-02,\n",
              "         -1.4511e-01,  1.2480e-01,  2.6626e-02,  1.0209e-01, -7.1794e-03,\n",
              "          6.4186e-02, -1.0668e-02,  4.0865e-02,  1.1676e-01, -1.1050e-01]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_input[0].size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "olt3bwC6044i",
        "outputId": "fbf98e24-53e1-4edb-fffe-b33480b4b8f2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 100])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get random 5 vals per seq and stack them all up \n",
        "pluck_vals = lambda x: x[0,torch.randperm(100)[:5]]\n",
        "random_vals = torch.cat([pluck_vals(x) for x in train_input]).numpy()\n",
        "print(random_vals.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7BIa0rAoImE7",
        "outputId": "5daaed8a-801b-45ed-f17d-bf5661236615"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(125000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "import numpy as np\n",
        "\n",
        "kmeans = KMeans(n_clusters=100, random_state=0).fit(random_vals[:,np.newaxis])\n",
        "kmeans.labels_\n",
        "\n",
        "\n",
        "kmeans.cluster_centers_.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTqsSl74IpaX",
        "outputId": "6e9e5dd0-6828-4657-c17f-a40584fb9634"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tarin_numpy = train_input[:5,:].view(-1,1).numpy()"
      ],
      "metadata": {
        "id": "gNEAMWR82toU"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.from_numpy(kmeans.predict(tarin_numpy)).view(5,-1).float()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8zfUmz6629qv",
        "outputId": "95c664de-01d1-449c-aa2b-88a91f7cc5e9"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[63.,  0., 76., 24.,  0., 24., 24., 63., 72., 93.,  0., 29.,  0., 93.,\n",
              "         93., 76., 89.,  6.,  6.,  6., 89.,  6., 29., 24., 63.,  4., 92., 26.,\n",
              "         49., 59., 98., 49., 26., 92.,  4., 63., 29., 72., 29., 63., 63., 37.,\n",
              "         50., 39., 46., 23., 44., 86., 60., 82., 24., 72., 63., 72.,  0.,  0.,\n",
              "         72., 29., 72., 76., 63., 63., 24., 72., 93., 63., 24., 72., 35., 35.,\n",
              "         35., 35., 35., 35., 22., 24., 29., 93., 76., 93., 72., 63., 29., 29.,\n",
              "          0., 76., 72., 72., 72., 76., 93., 63., 76., 29.,  0., 76.,  0., 76.,\n",
              "         63., 24.],\n",
              "        [76.,  0., 76., 63., 76., 93.,  0., 72., 63., 93.,  0., 63., 29., 29.,\n",
              "         76., 93., 93., 93., 24.,  0., 29., 63., 89., 38., 38., 38., 89., 89.,\n",
              "         89., 24., 29., 76., 72.,  0., 63., 43., 18., 81., 39.,  4., 34., 37.,\n",
              "         24., 63., 29., 63., 24., 76., 76., 29.,  0., 24., 76., 76., 24.,  0.,\n",
              "         24., 29., 76., 18., 88., 12., 77., 56., 88., 60., 93., 76., 24., 24.,\n",
              "         54., 54.,  1., 54., 54.,  1.,  1.,  1., 76., 24., 93., 24.,  0.,  0.,\n",
              "         29.,  0., 72., 72., 93.,  0., 29., 76.,  0., 93., 72., 93., 76., 72.,\n",
              "          0.,  0.],\n",
              "        [29., 76., 72.,  0.,  0., 63., 29., 93., 63., 72., 63., 24., 76., 63.,\n",
              "         76., 63., 76., 93., 63., 72., 76., 72., 29., 29., 24., 41., 41., 41.,\n",
              "         41., 90., 41., 50., 41., 50., 93., 72., 76., 63., 63.,  0., 93., 29.,\n",
              "          0., 20., 58., 58., 20., 58., 58., 20., 20., 58., 20., 58., 93., 76.,\n",
              "         72., 72., 72., 76., 76., 72., 24., 76., 93., 42., 88., 95., 98., 38.,\n",
              "         49., 94., 50., 93.,  0., 29., 24., 76., 76., 29., 63., 93., 76., 76.,\n",
              "         24., 72., 24., 16., 44., 71., 40., 23., 50., 76., 63., 76., 93., 72.,\n",
              "         93.,  0.],\n",
              "        [63.,  0., 63., 24., 29.,  0., 24.,  0., 76., 93., 29., 93., 76.,  0.,\n",
              "          0., 63., 72., 93., 93.,  0., 72., 76., 72., 72., 76., 93., 72., 29.,\n",
              "         29., 29., 72., 93., 24., 76., 76., 29., 92., 52., 92., 92., 92., 52.,\n",
              "         52., 72., 24., 63., 29., 76., 72., 76., 63., 72., 29.,  0., 74., 18.,\n",
              "         67., 62., 65., 62., 67., 18., 74.,  0., 29., 93., 93., 72., 63., 76.,\n",
              "         93., 72., 29., 41., 68., 47., 32., 26., 13., 93., 93., 76., 29., 24.,\n",
              "         29., 93., 24., 29., 63., 76.,  4., 81., 81.,  4., 81., 81.,  4., 93.,\n",
              "         29., 72.],\n",
              "        [24., 24., 82., 60., 90., 67., 57., 67., 90., 96., 42., 24., 76., 76.,\n",
              "         29., 24., 24., 63., 24., 76., 29.,  0., 76.,  0., 93., 29., 93., 29.,\n",
              "         29.,  4., 17., 15.,  6., 14., 10., 31., 23., 43., 29., 76., 76., 24.,\n",
              "         29., 76.,  0., 72., 76., 72., 72.,  0., 29., 29., 72., 29., 76., 29.,\n",
              "         80., 80., 54., 54., 80., 54., 93., 29., 63., 24.,  0., 63., 29., 63.,\n",
              "         72., 63., 93.,  0., 63., 29., 93., 76., 29., 63., 93., 24., 93., 93.,\n",
              "         88., 46., 88., 88., 46., 46., 88., 88., 46., 63., 72., 93.,  0.,  0.,\n",
              "         93., 93.]])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class SeqDataset(Dataset):\n",
        "    \"\"\"\n",
        "    wrap up seq dataset into our own, which will convert floating points into sequences of integers\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, inputs, targets, kmeans_clusters):\n",
        "        self.inputs = inputs\n",
        "        self.targets = targets\n",
        "        self.kmeans_clusters = kmeans_clusters\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.inputs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x, y = self.inputs[idx], self.targets[idx]\n",
        "        batch_size = x.shape[0]\n",
        "        x_np = x.view(-1,1).numpy()\n",
        "        y_np = y.view(-1,1).numpy()\n",
        "        x_clusters = torch.from_numpy(self.kmeans_clusters.predict(x_np)).view(batch_size,-1).long()\n",
        "        y_clusters = torch.from_numpy(self.kmeans_clusters.predict(y_np)).view(batch_size,-1).long()\n",
        "\n",
        "        return x_clusters.squeeze(), y_clusters.squeeze()"
      ],
      "metadata": {
        "id": "VWUv1riM1Sjc"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = SeqDataset(train_input, train_targets, kmeans)\n",
        "test_dataset = SeqDataset(test_input, test_targets, kmeans)\n",
        "train_dataset[0][0] # one example image flattened out into integers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSysm7cG39E7",
        "outputId": "ad7aed84-a7c6-457e-f5ce-18d87d3e4d09"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([63,  0, 76, 24,  0, 24, 24, 63, 72, 93,  0, 29,  0, 93, 93, 76, 89,  6,\n",
              "         6,  6, 89,  6, 29, 24, 63,  4, 92, 26, 49, 59, 98, 49, 26, 92,  4, 63,\n",
              "        29, 72, 29, 63, 63, 37, 50, 39, 46, 23, 44, 86, 60, 82, 24, 72, 63, 72,\n",
              "         0,  0, 72, 29, 72, 76, 63, 63, 24, 72, 93, 63, 24, 72, 35, 35, 35, 35,\n",
              "        35, 35, 22, 24, 29, 93, 76, 93, 72, 63, 29, 29,  0, 76, 72, 72, 72, 76,\n",
              "        93, 63, 76, 29,  0, 76,  0, 76, 63, 24])"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset[0][0].size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQc_prBq5sqV",
        "outputId": "0a0033b2-a737-45f4-8dcc-91d79a034827"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([100])"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from mingpt.model import GPT, GPTConfig\n",
        "block_size = 100\n",
        "num_clusters = 100\n",
        "mconf = GPTConfig(num_clusters, block_size,\n",
        "                  n_layer=2, n_head=4, n_embd=128)\n",
        "model = GPT(mconf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmLdj1Ym4aHc",
        "outputId": "2b8fd78a-4c37-45f6-b736-57bc4e863851"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "07/10/2022 06:58:56 - INFO - mingpt.model -   number of parameters: 4.352000e+05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from mingpt.trainer import Trainer, TrainerConfig\n",
        "\n",
        "# initialize a trainer instance and kick off training\n",
        "tconf = TrainerConfig(max_epochs=2, batch_size=32, learning_rate=6e-4,\n",
        "                      lr_decay=True, warmup_tokens=512*20, final_tokens=2*len(train_dataset)*block_size,\n",
        "                      num_workers=4)\n",
        "trainer = Trainer(model, train_dataset, None, tconf)\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "id": "op7rQ4uf4kbD",
        "outputId": "84cd2ecf-bd29-4957-b168-7c31e782a806"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "epoch 1 iter 13: train loss 3.57745. lr 5.999290e-04:   2%|▏         | 14/782 [00:05<05:28,  2.33it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-fa971c47b007>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m                       num_workers=4)\n\u001b[1;32m      7\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/hacking-minGPT/mingpt/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m             \u001b[0mrun_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_dataset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m                 \u001b[0mtest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/hacking-minGPT/mingpt/trainer.py\u001b[0m in \u001b[0;36mrun_epoch\u001b[0;34m(loader, is_train)\u001b[0m\n\u001b[1;32m     83\u001b[0m                     \u001b[0;31m# backprop and update the parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m                     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m                     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m                     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad_norm_clip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    361\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m def grad(\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7o-ymc65XvK",
        "outputId": "44ff7def-df6b-4ab8-c6ac-c445aeaee952"
      },
      "execution_count": 44,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "> \u001b[0;32m/content/hacking-minGPT/mingpt/model.py\u001b[0m(212)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m    210 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m    211 \u001b[0;31m    \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m--> 212 \u001b[0;31m        \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m    213 \u001b[0;31m        \u001b[0;32massert\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Cannot forward, model block size is exhausted.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m    214 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\n",
            "ipdb> idx\n",
            "tensor([[[63,  0, 76,  ..., 76, 24, 63]],\n",
            "\n",
            "        [[93, 29, 24,  ..., 72, 24, 72]],\n",
            "\n",
            "        [[93, 93, 63,  ..., 63, 63, 24]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[76, 24,  0,  ..., 93, 24, 72]],\n",
            "\n",
            "        [[76,  0, 24,  ..., 24, 93, 29]],\n",
            "\n",
            "        [[76, 24,  0,  ...,  0, 76,  0]]], dtype=torch.int32)\n",
            "ipdb> idx.size()\n",
            "torch.Size([32, 1, 100])\n",
            "ipdb> q\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "0BGu4icZ5iyU"
      },
      "execution_count": 44,
      "outputs": []
    }
  ]
}